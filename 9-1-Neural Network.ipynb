{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:/Users/H_jam/OneDrive/Uni-MA/Term2/DataMining/DataSets/DeepLearning/Artificial_Neural_Networks/Churn_Modelling.csv')\n",
    "\n",
    "\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "onehotencoder = ColumnTransformer([('one_hot_encoder',OneHotEncoder(categories= 'auto'),[1])], remainder = 'passthrough')\n",
    "X = onehotencoder.fit_transform(X)\n",
    "X = X[:, 1:]\n",
    "X = np.array(X, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "onehotencoder = ColumnTransformer([('one_hot_encoder',OneHotEncoder(categories= 'auto'),[1])], remainder = 'passthrough')\n",
    "X = onehotencoder.fit_transform(X)\n",
    "X = X[:, 1:]\n",
    "X = np.array(X, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#unique, counts = np.unique(y_test, return_counts=True)\n",
    "#dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Making ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the keras and packages\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ایجاد شبکه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and first hidden layer\n",
    "\n",
    "classifier.add(Dense(units = 6, activation = 'relu', kernel_initializer= 'uniform', input_dim = 11))\n",
    "# ورودی ها همون تعداد فیچرهاست"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "\n",
    "classifier.add(Dense(units = 6, activation = 'relu', kernel_initializer= 'uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer= 'uniform'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the ANN\n",
    "\n",
    "classifier.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 688us/step - loss: 0.4869 - accuracy: 0.7960\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 1s 686us/step - loss: 0.4275 - accuracy: 0.7960\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 1s 671us/step - loss: 0.4213 - accuracy: 0.8020\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 1s 664us/step - loss: 0.4173 - accuracy: 0.8207\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.4151 - accuracy: 0.8265\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 1s 665us/step - loss: 0.4133 - accuracy: 0.8303\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.4116 - accuracy: 0.8331\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 1s 659us/step - loss: 0.4101 - accuracy: 0.8328\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 1s 666us/step - loss: 0.4089 - accuracy: 0.8336\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 1s 684us/step - loss: 0.4078 - accuracy: 0.8341\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 1s 672us/step - loss: 0.4074 - accuracy: 0.8336\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.4068 - accuracy: 0.8357\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 1s 662us/step - loss: 0.4059 - accuracy: 0.8346\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.4054 - accuracy: 0.8357\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 1s 717us/step - loss: 0.4049 - accuracy: 0.8349\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 1s 685us/step - loss: 0.4045 - accuracy: 0.8349\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 1s 670us/step - loss: 0.4044 - accuracy: 0.8356\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.4037 - accuracy: 0.8346\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 1s 665us/step - loss: 0.4037 - accuracy: 0.8361\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 1s 662us/step - loss: 0.4039 - accuracy: 0.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8b7856bd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size= 10, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 606us/step\n"
     ]
    }
   ],
   "source": [
    "# Part 3 -Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred >0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H_jam\\AppData\\Local\\Temp\\ipykernel_23140\\3298723986.py:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=build_clf)\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def build_clf(unit):\n",
    "  # creating the layers of the NN\n",
    "  ann = keras.models.Sequential()\n",
    "  ann.add(keras.layers.Dense(units=unit, activation='relu'))\n",
    "  ann.add(keras.layers.Dense(units=unit, activation='relu'))\n",
    "  ann.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "  ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return ann\n",
    "\n",
    "model = KerasClassifier(build_fn=build_clf)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params={'batch_size':[100, 20, 50], \n",
    "        'nb_epoch':[20, 10],\n",
    "        'unit':[5, 10, 15],\n",
    "           \n",
    "        }\n",
    "gs=GridSearchCV(estimator=model, param_grid=params, cv=10, scoring= 'accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now fit the dataset to the GridSearchCV object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 741us/step - loss: 0.7810 - accuracy: 0.4031\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 776us/step - loss: 0.6558 - accuracy: 0.6432\n",
      "25/25 [==============================] - 0s 710us/step\n",
      "72/72 [==============================] - 1s 833us/step - loss: 0.6546 - accuracy: 0.7412\n",
      "25/25 [==============================] - 0s 563us/step\n",
      "72/72 [==============================] - 1s 854us/step - loss: 0.7449 - accuracy: 0.4667\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 762us/step - loss: 0.6418 - accuracy: 0.6547\n",
      "25/25 [==============================] - 0s 646us/step\n",
      "72/72 [==============================] - 1s 769us/step - loss: 0.6680 - accuracy: 0.6276\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 813us/step - loss: 0.5620 - accuracy: 0.7951\n",
      "25/25 [==============================] - 0s 794us/step\n",
      "72/72 [==============================] - 1s 867us/step - loss: 0.5812 - accuracy: 0.7435\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 869us/step - loss: 0.6442 - accuracy: 0.6451\n",
      "25/25 [==============================] - 0s 647us/step\n",
      "72/72 [==============================] - 1s 840us/step - loss: 0.7041 - accuracy: 0.5260\n",
      "25/25 [==============================] - 0s 589us/step\n",
      "72/72 [==============================] - 1s 876us/step - loss: 0.5951 - accuracy: 0.7329\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 807us/step - loss: 0.6145 - accuracy: 0.6817\n",
      "25/25 [==============================] - 0s 607us/step\n",
      "72/72 [==============================] - 1s 952us/step - loss: 0.7986 - accuracy: 0.3822\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 827us/step - loss: 0.6589 - accuracy: 0.6136\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 826us/step - loss: 0.6065 - accuracy: 0.7233\n",
      "25/25 [==============================] - 0s 634us/step\n",
      "72/72 [==============================] - 1s 790us/step - loss: 0.6914 - accuracy: 0.5640\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "72/72 [==============================] - 1s 826us/step - loss: 0.7821 - accuracy: 0.4039\n",
      "25/25 [==============================] - 0s 582us/step\n",
      "72/72 [==============================] - 1s 807us/step - loss: 0.7937 - accuracy: 0.4390\n",
      "25/25 [==============================] - 0s 600us/step\n",
      "72/72 [==============================] - 1s 868us/step - loss: 0.6581 - accuracy: 0.6174\n",
      "25/25 [==============================] - 0s 561us/step\n",
      "72/72 [==============================] - 1s 833us/step - loss: 0.6528 - accuracy: 0.6167\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 862us/step - loss: 0.7282 - accuracy: 0.5668\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 976us/step - loss: 0.5720 - accuracy: 0.7608\n",
      "25/25 [==============================] - 0s 647us/step\n",
      "72/72 [==============================] - 1s 924us/step - loss: 0.5664 - accuracy: 0.7593\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 861us/step - loss: 0.7062 - accuracy: 0.5178\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 805us/step - loss: 0.5316 - accuracy: 0.7757\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 868us/step - loss: 0.8440 - accuracy: 0.4906\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 875us/step - loss: 0.7070 - accuracy: 0.5150\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 847us/step - loss: 0.7287 - accuracy: 0.5238\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 846us/step - loss: 0.6146 - accuracy: 0.6989\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "72/72 [==============================] - 1s 839us/step - loss: 0.6325 - accuracy: 0.6554\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "72/72 [==============================] - 1s 847us/step - loss: 0.5922 - accuracy: 0.7240\n",
      "25/25 [==============================] - 0s 625us/step\n",
      "72/72 [==============================] - 1s 814us/step - loss: 0.6254 - accuracy: 0.7362\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "72/72 [==============================] - 1s 847us/step - loss: 0.7102 - accuracy: 0.5964\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 848us/step - loss: 0.7520 - accuracy: 0.5938\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "72/72 [==============================] - 1s 804us/step - loss: 0.5987 - accuracy: 0.7604\n",
      "25/25 [==============================] - 0s 564us/step\n",
      "72/72 [==============================] - 1s 832us/step - loss: 0.6344 - accuracy: 0.7758\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 849us/step - loss: 0.6881 - accuracy: 0.5088\n",
      "25/25 [==============================] - 0s 604us/step\n",
      "72/72 [==============================] - 1s 805us/step - loss: 0.7101 - accuracy: 0.5254\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "72/72 [==============================] - 1s 875us/step - loss: 0.6648 - accuracy: 0.6958\n",
      "25/25 [==============================] - 0s 583us/step\n",
      "72/72 [==============================] - 1s 804us/step - loss: 0.6115 - accuracy: 0.7206\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 819us/step - loss: 0.6488 - accuracy: 0.6597\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "72/72 [==============================] - 1s 811us/step - loss: 0.8150 - accuracy: 0.3151\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "72/72 [==============================] - 1s 797us/step - loss: 0.6250 - accuracy: 0.6774\n",
      "25/25 [==============================] - 0s 604us/step\n",
      "72/72 [==============================] - 1s 776us/step - loss: 0.5363 - accuracy: 0.7639\n",
      "25/25 [==============================] - 0s 625us/step\n",
      "72/72 [==============================] - 1s 783us/step - loss: 0.7155 - accuracy: 0.5407\n",
      "25/25 [==============================] - 0s 564us/step\n",
      "72/72 [==============================] - 1s 782us/step - loss: 0.5438 - accuracy: 0.7937\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 762us/step - loss: 0.5996 - accuracy: 0.7399\n",
      "25/25 [==============================] - 0s 565us/step\n",
      "72/72 [==============================] - 1s 785us/step - loss: 0.5648 - accuracy: 0.7494\n",
      "25/25 [==============================] - 0s 627us/step\n",
      "72/72 [==============================] - 1s 762us/step - loss: 0.6225 - accuracy: 0.6771\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "72/72 [==============================] - 1s 769us/step - loss: 0.8424 - accuracy: 0.3042\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "72/72 [==============================] - 1s 979us/step - loss: 0.5528 - accuracy: 0.7678\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 769us/step - loss: 0.5635 - accuracy: 0.7808\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "72/72 [==============================] - 1s 847us/step - loss: 0.5729 - accuracy: 0.7414\n",
      "25/25 [==============================] - 0s 607us/step\n",
      "72/72 [==============================] - 1s 833us/step - loss: 0.7331 - accuracy: 0.5024\n",
      "25/25 [==============================] - 0s 604us/step\n",
      "72/72 [==============================] - 1s 823us/step - loss: 0.7856 - accuracy: 0.5018\n",
      "25/25 [==============================] - 0s 604us/step\n",
      "72/72 [==============================] - 1s 896us/step - loss: 0.5586 - accuracy: 0.7821\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "72/72 [==============================] - 1s 826us/step - loss: 0.5340 - accuracy: 0.7912\n",
      "25/25 [==============================] - 0s 582us/step\n",
      "72/72 [==============================] - 1s 805us/step - loss: 0.5570 - accuracy: 0.7778\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "72/72 [==============================] - 1s 797us/step - loss: 0.5168 - accuracy: 0.7914\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "72/72 [==============================] - 1s 798us/step - loss: 0.5443 - accuracy: 0.7763\n",
      "25/25 [==============================] - 0s 648us/step\n",
      "360/360 [==============================] - 1s 719us/step - loss: 0.5522 - accuracy: 0.7093\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "360/360 [==============================] - 1s 752us/step - loss: 0.5593 - accuracy: 0.7542\n",
      "25/25 [==============================] - 0s 604us/step\n",
      "360/360 [==============================] - 1s 930us/step - loss: 0.5247 - accuracy: 0.7908\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "360/360 [==============================] - 1s 740us/step - loss: 0.5199 - accuracy: 0.7900\n",
      "25/25 [==============================] - 0s 564us/step\n",
      "360/360 [==============================] - 1s 743us/step - loss: 0.5603 - accuracy: 0.7600\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 744us/step - loss: 0.6931 - accuracy: 0.6678\n",
      "25/25 [==============================] - 0s 588us/step\n",
      "360/360 [==============================] - 1s 756us/step - loss: 0.7055 - accuracy: 0.5926\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 753us/step - loss: 0.5381 - accuracy: 0.7653\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "360/360 [==============================] - 1s 776us/step - loss: 0.5119 - accuracy: 0.7957\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "360/360 [==============================] - 1s 750us/step - loss: 0.5464 - accuracy: 0.7950\n",
      "25/25 [==============================] - 0s 683us/step\n",
      "360/360 [==============================] - 1s 791us/step - loss: 0.5909 - accuracy: 0.6983\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 775us/step - loss: 0.5168 - accuracy: 0.7643\n",
      "25/25 [==============================] - 0s 604us/step\n",
      "360/360 [==============================] - 1s 753us/step - loss: 0.6606 - accuracy: 0.6169\n",
      "25/25 [==============================] - 0s 647us/step\n",
      "360/360 [==============================] - 1s 746us/step - loss: 0.5527 - accuracy: 0.7294\n",
      "25/25 [==============================] - 0s 604us/step\n",
      "360/360 [==============================] - 1s 748us/step - loss: 0.5083 - accuracy: 0.7851\n",
      "25/25 [==============================] - 0s 625us/step\n",
      "360/360 [==============================] - 1s 796us/step - loss: 0.5129 - accuracy: 0.7713\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "360/360 [==============================] - 1s 746us/step - loss: 0.4772 - accuracy: 0.7969\n",
      "25/25 [==============================] - 0s 876us/step\n",
      "360/360 [==============================] - 1s 734us/step - loss: 0.5213 - accuracy: 0.7658\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "360/360 [==============================] - 1s 727us/step - loss: 0.5437 - accuracy: 0.7567\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 706us/step - loss: 0.5157 - accuracy: 0.7815\n",
      "25/25 [==============================] - 0s 564us/step\n",
      "360/360 [==============================] - 1s 722us/step - loss: 0.4824 - accuracy: 0.7935\n",
      "25/25 [==============================] - 0s 565us/step\n",
      "360/360 [==============================] - 1s 697us/step - loss: 0.5049 - accuracy: 0.7707\n",
      "25/25 [==============================] - 0s 562us/step\n",
      "360/360 [==============================] - 1s 707us/step - loss: 0.4861 - accuracy: 0.7969\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 716us/step - loss: 0.4619 - accuracy: 0.8042\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "360/360 [==============================] - 1s 731us/step - loss: 0.5261 - accuracy: 0.7639\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 750us/step - loss: 0.5210 - accuracy: 0.7761\n",
      "25/25 [==============================] - 0s 582us/step\n",
      "360/360 [==============================] - 1s 722us/step - loss: 0.4996 - accuracy: 0.7928\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 731us/step - loss: 0.5048 - accuracy: 0.7639\n",
      "25/25 [==============================] - 0s 607us/step\n",
      "360/360 [==============================] - 1s 734us/step - loss: 0.5271 - accuracy: 0.7503\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 734us/step - loss: 0.5224 - accuracy: 0.7482\n",
      "25/25 [==============================] - 0s 546us/step\n",
      "360/360 [==============================] - 1s 720us/step - loss: 0.6470 - accuracy: 0.6635\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 730us/step - loss: 0.5699 - accuracy: 0.7483\n",
      "25/25 [==============================] - 0s 625us/step\n",
      "360/360 [==============================] - 1s 712us/step - loss: 0.5804 - accuracy: 0.7275\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 697us/step - loss: 0.5705 - accuracy: 0.7857\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "360/360 [==============================] - 1s 720us/step - loss: 0.5450 - accuracy: 0.7717\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 692us/step - loss: 0.5874 - accuracy: 0.7636\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 715us/step - loss: 0.5486 - accuracy: 0.7514\n",
      "25/25 [==============================] - 0s 542us/step\n",
      "360/360 [==============================] - 1s 688us/step - loss: 0.5857 - accuracy: 0.7375\n",
      "25/25 [==============================] - 0s 625us/step\n",
      "360/360 [==============================] - 1s 716us/step - loss: 0.5564 - accuracy: 0.7807\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 698us/step - loss: 0.6250 - accuracy: 0.7160\n",
      "25/25 [==============================] - 0s 586us/step\n",
      "360/360 [==============================] - 1s 713us/step - loss: 0.5037 - accuracy: 0.7925\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "360/360 [==============================] - 1s 719us/step - loss: 0.5279 - accuracy: 0.7867\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 743us/step - loss: 0.5171 - accuracy: 0.7903\n",
      "25/25 [==============================] - 0s 625us/step\n",
      "360/360 [==============================] - 1s 742us/step - loss: 0.4683 - accuracy: 0.7961\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "360/360 [==============================] - 1s 743us/step - loss: 0.5516 - accuracy: 0.7344\n",
      "25/25 [==============================] - 0s 627us/step\n",
      "360/360 [==============================] - 1s 719us/step - loss: 0.5061 - accuracy: 0.7896\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "360/360 [==============================] - 1s 751us/step - loss: 0.5238 - accuracy: 0.7740\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "360/360 [==============================] - 1s 749us/step - loss: 0.5067 - accuracy: 0.7962\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "360/360 [==============================] - 1s 726us/step - loss: 0.5114 - accuracy: 0.7569\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "360/360 [==============================] - 1s 779us/step - loss: 0.5247 - accuracy: 0.7760\n",
      "25/25 [==============================] - 0s 564us/step\n",
      "360/360 [==============================] - 1s 733us/step - loss: 0.4970 - accuracy: 0.7807\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 737us/step - loss: 0.4801 - accuracy: 0.7949\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 741us/step - loss: 0.5429 - accuracy: 0.7424\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "360/360 [==============================] - 1s 739us/step - loss: 0.4907 - accuracy: 0.7939\n",
      "25/25 [==============================] - 0s 585us/step\n",
      "360/360 [==============================] - 1s 733us/step - loss: 0.4966 - accuracy: 0.7851\n",
      "25/25 [==============================] - 0s 627us/step\n",
      "360/360 [==============================] - 1s 735us/step - loss: 0.4856 - accuracy: 0.7962\n",
      "25/25 [==============================] - 0s 543us/step\n",
      "360/360 [==============================] - 1s 818us/step - loss: 0.5030 - accuracy: 0.7799\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "360/360 [==============================] - 1s 765us/step - loss: 0.4888 - accuracy: 0.7939\n",
      "25/25 [==============================] - 0s 628us/step\n",
      "360/360 [==============================] - 1s 761us/step - loss: 0.4679 - accuracy: 0.8047\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "360/360 [==============================] - 1s 797us/step - loss: 0.4934 - accuracy: 0.7753\n",
      "25/25 [==============================] - 0s 626us/step\n",
      "144/144 [==============================] - 1s 778us/step - loss: 0.6642 - accuracy: 0.5894\n",
      "25/25 [==============================] - 0s 605us/step\n",
      "144/144 [==============================] - 1s 771us/step - loss: 0.5707 - accuracy: 0.7303\n",
      "25/25 [==============================] - 0s 587us/step\n",
      "144/144 [==============================] - 1s 756us/step - loss: 0.5643 - accuracy: 0.7956\n",
      "25/25 [==============================] - 0s 648us/step\n",
      "144/144 [==============================] - 1s 797us/step - loss: 0.5640 - accuracy: 0.7975\n",
      "25/25 [==============================] - 0s 627us/step\n",
      "144/144 [==============================] - 1s 757us/step - loss: 0.9245 - accuracy: 0.3375\n",
      "25/25 [==============================] - 0s 625us/step\n",
      "144/144 [==============================] - 1s 806us/step - loss: 0.5181 - accuracy: 0.7935\n",
      "25/25 [==============================] - 0s 606us/step\n",
      "144/144 [==============================] - 1s 760us/step - loss: 0.7280 - accuracy: 0.5317\n",
      "25/25 [==============================] - 0s 584us/step\n",
      "144/144 [==============================] - 1s 754us/step - loss: 0.6669 - accuracy: 0.7306\n",
      "25/25 [==============================] - 0s 668us/step\n",
      "144/144 [==============================] - 1s 740us/step - loss: 0.6039 - accuracy: 0.7122\n",
      "25/25 [==============================] - 0s 564us/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# now fit the dataset to the GridSearchCV object. \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m gs \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m best_params\u001b[39m=\u001b[39mgs\u001b[39m.\u001b[39mbest_params_\n\u001b[0;32m      5\u001b[0m accuracy\u001b[39m=\u001b[39mgs\u001b[39m.\u001b[39mbest_score_\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape for y: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py:164\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn(\n\u001b[0;32m    161\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m)\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_fn))\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    167\u001b[0m     losses\u001b[39m.\u001b[39mis_categorical_crossentropy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mloss)\n\u001b[0;32m    168\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(y\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    169\u001b[0m ):\n\u001b[0;32m    170\u001b[0m     y \u001b[39m=\u001b[39m to_categorical(y)\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36mbuild_clf\u001b[1;34m(unit)\u001b[0m\n\u001b[0;32m      6\u001b[0m ann\u001b[39m.\u001b[39madd(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39munit, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m ann\u001b[39m.\u001b[39madd(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m ann\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m ann\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\engine\\training.py:738\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss \u001b[39m=\u001b[39m loss\n\u001b[0;32m    737\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss \u001b[39m=\u001b[39m compile_utils\u001b[39m.\u001b[39mLossesContainer(\n\u001b[0;32m    739\u001b[0m         loss, loss_weights, output_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_names\n\u001b[0;32m    740\u001b[0m     )\n\u001b[0;32m    741\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_metrics \u001b[39m=\u001b[39m compile_utils\u001b[39m.\u001b[39mMetricsContainer(\n\u001b[0;32m    742\u001b[0m     metrics,\n\u001b[0;32m    743\u001b[0m     weighted_metrics,\n\u001b[0;32m    744\u001b[0m     output_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_names,\n\u001b[0;32m    745\u001b[0m     from_serialized\u001b[39m=\u001b[39mfrom_serialized,\n\u001b[0;32m    746\u001b[0m )\n\u001b[0;32m    748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_steps_per_execution(steps_per_execution \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\engine\\compile_utils.py:131\u001b[0m, in \u001b[0;36mLossesContainer.__init__\u001b[1;34m(self, losses, loss_weights, output_names, total_loss_mean)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_per_output_metrics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Per-output losses become metrics.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# Mean of the total loss.\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_loss_mean \u001b[39m=\u001b[39m total_loss_mean \u001b[39mor\u001b[39;00m metrics_mod\u001b[39m.\u001b[39mMean(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_built \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\dtensor\\utils.py:144\u001b[0m, in \u001b[0;36minject_mesh.<locals>._wrap_function\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m mesh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     instance\u001b[39m.\u001b[39m_mesh \u001b[39m=\u001b[39m mesh\n\u001b[1;32m--> 144\u001b[0m init_method(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\metrics\\base_metric.py:613\u001b[0m, in \u001b[0;36mMean.__init__\u001b[1;34m(self, name, dtype)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[39m@dtensor_utils\u001b[39m\u001b[39m.\u001b[39minject_mesh\n\u001b[0;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 613\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    614\u001b[0m         reduction\u001b[39m=\u001b[39mmetrics_utils\u001b[39m.\u001b[39mReduction\u001b[39m.\u001b[39mWEIGHTED_MEAN,\n\u001b[0;32m    615\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    616\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    617\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\metrics\\base_metric.py:430\u001b[0m, in \u001b[0;36mReduce.__init__\u001b[1;34m(self, reduction, name, dtype)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(name\u001b[39m=\u001b[39mname, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction \u001b[39m=\u001b[39m reduction\n\u001b[1;32m--> 430\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\u001b[39m\"\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m\"\u001b[39m, initializer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m reduction \u001b[39min\u001b[39;00m [\n\u001b[0;32m    432\u001b[0m     metrics_utils\u001b[39m.\u001b[39mReduction\u001b[39m.\u001b[39mSUM_OVER_BATCH_SIZE,\n\u001b[0;32m    433\u001b[0m     metrics_utils\u001b[39m.\u001b[39mReduction\u001b[39m.\u001b[39mWEIGHTED_MEAN,\n\u001b[0;32m    434\u001b[0m ]:\n\u001b[0;32m    435\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m, initializer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\metrics\\base_metric.py:366\u001b[0m, in \u001b[0;36mMetric.add_weight\u001b[1;34m(self, name, shape, aggregation, synchronization, initializer, dtype)\u001b[0m\n\u001b[0;32m    363\u001b[0m     additional_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m    365\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    367\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    368\u001b[0m         shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    369\u001b[0m         dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype,\n\u001b[0;32m    370\u001b[0m         trainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    371\u001b[0m         initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    372\u001b[0m         collections\u001b[39m=\u001b[39m[],\n\u001b[0;32m    373\u001b[0m         synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m    374\u001b[0m         aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m    375\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39madditional_kwargs,\n\u001b[0;32m    376\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\engine\\base_layer.py:712\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m    710\u001b[0m     getter \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(getter, layout\u001b[39m=\u001b[39mlayout)\n\u001b[1;32m--> 712\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_variable_with_custom_getter(\n\u001b[0;32m    713\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    714\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    715\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m     getter\u001b[39m=\u001b[39mgetter,\n\u001b[0;32m    718\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m     overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    720\u001b[0m     initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    721\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    722\u001b[0m     constraint\u001b[39m=\u001b[39mconstraint,\n\u001b[0;32m    723\u001b[0m     trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m    724\u001b[0m     use_resource\u001b[39m=\u001b[39muse_resource,\n\u001b[0;32m    725\u001b[0m     collections\u001b[39m=\u001b[39mcollections_arg,\n\u001b[0;32m    726\u001b[0m     synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m    727\u001b[0m     aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m    728\u001b[0m     caching_device\u001b[39m=\u001b[39mcaching_device,\n\u001b[0;32m    729\u001b[0m )\n\u001b[0;32m    730\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[: variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:489\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    479\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    480\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    481\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[0;32m    487\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[1;32m--> 489\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[0;32m    490\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    491\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    492\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    493\u001b[0m     initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    494\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_for_getter)\n\u001b[0;32m    496\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\engine\\base_layer_utils.py:134\u001b[0m, in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout)\u001b[0m\n\u001b[0;32m    127\u001b[0m     use_resource \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m layout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[39m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[39m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[39m# However, this breaks legacy (Estimator) checkpoints because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     \u001b[39m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m tf1\u001b[39m.\u001b[39mVariable(\n\u001b[0;32m    135\u001b[0m         initial_value\u001b[39m=\u001b[39minit_val,\n\u001b[0;32m    136\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    137\u001b[0m         trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m    138\u001b[0m         caching_device\u001b[39m=\u001b[39mcaching_device,\n\u001b[0;32m    139\u001b[0m         dtype\u001b[39m=\u001b[39mvariable_dtype,\n\u001b[0;32m    140\u001b[0m         validate_shape\u001b[39m=\u001b[39mvalidate_shape,\n\u001b[0;32m    141\u001b[0m         constraint\u001b[39m=\u001b[39mconstraint,\n\u001b[0;32m    142\u001b[0m         use_resource\u001b[39m=\u001b[39muse_resource,\n\u001b[0;32m    143\u001b[0m         collections\u001b[39m=\u001b[39mcollections,\n\u001b[0;32m    144\u001b[0m         synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m    145\u001b[0m         aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m    146\u001b[0m         shape\u001b[39m=\u001b[39mvariable_shape \u001b[39mif\u001b[39;00m variable_shape \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m dtensor\u001b[39m.\u001b[39mDVariable(\n\u001b[0;32m    150\u001b[0m         initial_value\u001b[39m=\u001b[39minit_val,\n\u001b[0;32m    151\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         shape\u001b[39m=\u001b[39mvariable_shape \u001b[39mif\u001b[39;00m variable_shape \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\variables.py:285\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[0;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    284\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m VariableV1:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v1_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    286\u001b[0m   \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[0;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\variables.py:226\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[1;32m--> 226\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[0;32m    227\u001b[0m     initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m    228\u001b[0m     trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m    229\u001b[0m     collections\u001b[39m=\u001b[39mcollections,\n\u001b[0;32m    230\u001b[0m     validate_shape\u001b[39m=\u001b[39mvalidate_shape,\n\u001b[0;32m    231\u001b[0m     caching_device\u001b[39m=\u001b[39mcaching_device,\n\u001b[0;32m    232\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    233\u001b[0m     variable_def\u001b[39m=\u001b[39mvariable_def,\n\u001b[0;32m    234\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    235\u001b[0m     expected_shape\u001b[39m=\u001b[39mexpected_shape,\n\u001b[0;32m    236\u001b[0m     import_scope\u001b[39m=\u001b[39mimport_scope,\n\u001b[0;32m    237\u001b[0m     constraint\u001b[39m=\u001b[39mconstraint,\n\u001b[0;32m    238\u001b[0m     use_resource\u001b[39m=\u001b[39muse_resource,\n\u001b[0;32m    239\u001b[0m     synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m    240\u001b[0m     aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m    241\u001b[0m     shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\variables.py:66\u001b[0m, in \u001b[0;36m_make_getter.<locals>.getter\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 66\u001b[0m   \u001b[39mreturn\u001b[39;00m captured_getter(captured_previous, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3611\u001b[0m, in \u001b[0;36m_DefaultDistributionContext.__init__.<locals>.creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   3609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreator\u001b[39m(next_creator, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3610\u001b[0m   _require_strategy_scope_strategy(strategy)\n\u001b[1;32m-> 3611\u001b[0m   \u001b[39mreturn\u001b[39;00m next_creator(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\variables.py:219\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v1_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[0;32m    203\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    204\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[0;32m    217\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    218\u001b[0m   \u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: default_variable_creator(\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    220\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2707\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2705\u001b[0m \u001b[39mif\u001b[39;00m use_resource:\n\u001b[0;32m   2706\u001b[0m   distribute_strategy \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdistribute_strategy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2707\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39mResourceVariable(\n\u001b[0;32m   2708\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   2709\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m   2710\u001b[0m       collections\u001b[39m=\u001b[39mcollections,\n\u001b[0;32m   2711\u001b[0m       validate_shape\u001b[39m=\u001b[39mvalidate_shape,\n\u001b[0;32m   2712\u001b[0m       caching_device\u001b[39m=\u001b[39mcaching_device,\n\u001b[0;32m   2713\u001b[0m       name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   2714\u001b[0m       dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   2715\u001b[0m       constraint\u001b[39m=\u001b[39mconstraint,\n\u001b[0;32m   2716\u001b[0m       variable_def\u001b[39m=\u001b[39mvariable_def,\n\u001b[0;32m   2717\u001b[0m       import_scope\u001b[39m=\u001b[39mimport_scope,\n\u001b[0;32m   2718\u001b[0m       distribute_strategy\u001b[39m=\u001b[39mdistribute_strategy,\n\u001b[0;32m   2719\u001b[0m       synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m   2720\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   2721\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n\u001b[0;32m   2722\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2723\u001b[0m   \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39mRefVariable(\n\u001b[0;32m   2724\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   2725\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2736\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   2737\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\variables.py:289\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(VariableMetaclass, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1768\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape, handle, experimental_enable_variable_lifting)\u001b[0m\n\u001b[0;32m   1763\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_handle(trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m   1764\u001b[0m                          shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m   1765\u001b[0m                          dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1766\u001b[0m                          handle\u001b[39m=\u001b[39mhandle)\n\u001b[0;32m   1767\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1768\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_args(\n\u001b[0;32m   1769\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   1770\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m   1771\u001b[0m       collections\u001b[39m=\u001b[39mcollections,\n\u001b[0;32m   1772\u001b[0m       caching_device\u001b[39m=\u001b[39mcaching_device,\n\u001b[0;32m   1773\u001b[0m       name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   1774\u001b[0m       dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1775\u001b[0m       constraint\u001b[39m=\u001b[39mconstraint,\n\u001b[0;32m   1776\u001b[0m       synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[0;32m   1777\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   1778\u001b[0m       shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m   1779\u001b[0m       distribute_strategy\u001b[39m=\u001b[39mdistribute_strategy,\n\u001b[0;32m   1780\u001b[0m       validate_shape\u001b[39m=\u001b[39mvalidate_shape,\n\u001b[0;32m   1781\u001b[0m       experimental_enable_variable_lifting\u001b[39m=\u001b[39mexperimental_enable_variable_lifting,\n\u001b[0;32m   1782\u001b[0m       )\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1952\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape, experimental_enable_variable_lifting)\u001b[0m\n\u001b[0;32m   1950\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mInitializer\u001b[39m\u001b[39m\"\u001b[39m), device_context_manager(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1951\u001b[0m   \u001b[39mif\u001b[39;00m init_from_fn:\n\u001b[1;32m-> 1952\u001b[0m     initial_value \u001b[39m=\u001b[39m initial_value()\n\u001b[0;32m   1953\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(initial_value, trackable\u001b[39m.\u001b[39mCheckpointInitialValue):\n\u001b[0;32m   1954\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\initializers\\initializers.py:171\u001b[0m, in \u001b[0;36mZeros.__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m    168\u001b[0m     \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39mcall_with_layout(\n\u001b[0;32m    169\u001b[0m         tf\u001b[39m.\u001b[39mzeros, layout, shape\u001b[39m=\u001b[39mshape, dtype\u001b[39m=\u001b[39mdtype\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mzeros(shape, dtype)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2987\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2986\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2987\u001b[0m   tensor \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2988\u001b[0m   tensor\u001b[39m.\u001b[39m_is_zeros_tensor \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2989\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3048\u001b[0m, in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   3046\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shape\u001b[39m.\u001b[39m_shape_tuple():\n\u001b[0;32m   3047\u001b[0m     shape \u001b[39m=\u001b[39m reshape(shape, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])  \u001b[39m# Ensure it's a vector\u001b[39;00m\n\u001b[1;32m-> 3048\u001b[0m   output \u001b[39m=\u001b[39m fill(shape, constant(zero, dtype\u001b[39m=\u001b[39mdtype), name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   3049\u001b[0m \u001b[39massert\u001b[39;00m output\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype \u001b[39m==\u001b[39m dtype\n\u001b[0;32m   3050\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:240\u001b[0m, in \u001b[0;36mfill\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfill\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    202\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfill\u001b[39m(dims, value, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    204\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Creates a tensor filled with a scalar value.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[39m  See also `tf.ones`, `tf.zeros`, `tf.one_hot`, `tf.eye`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39m  @end_compatibility\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39mfill(dims, value, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    241\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, dims)\n\u001b[0;32m    242\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\H_jam\\.conda\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:4127\u001b[0m, in \u001b[0;36mfill\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m   4125\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   4126\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 4127\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m   4128\u001b[0m       _ctx, \u001b[39m\"\u001b[39m\u001b[39mFill\u001b[39m\u001b[39m\"\u001b[39m, name, dims, value)\n\u001b[0;32m   4129\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   4130\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# now fit the dataset to the GridSearchCV object. \n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "best_params=gs.best_params_\n",
    "accuracy=gs.best_score_\n",
    "print(best_params)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint('best', monitor = 'val_accuracy', mode = 'max', save_best_only = True, verbose = 0)\n",
    "\n",
    "classifier.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "print('Training model ...')\n",
    "\n",
    "r = classifier.fit(X_train, y_train, epochs = 20, batch_size = 64, validation_data = (X_test, y_test), callbacks = [mc])\n",
    "from keras.models import load_model\n",
    "best = load_model('best')\n",
    "\n",
    "\n",
    "# plot loss per iteration\n",
    "plt.plot(r.history['loss'], label = 'loss')\n",
    "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()\n",
    "\n",
    "# plot accuracy per iteration\n",
    "\n",
    "plt.plot(r.history['accuracy'], label = 'acc')\n",
    "plt.plot(r.history['val_accuracy'], label = 'val_acc')\n",
    "plt.legend()\n",
    "\n",
    "# Check the best obtained model\n",
    "\n",
    "best.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
